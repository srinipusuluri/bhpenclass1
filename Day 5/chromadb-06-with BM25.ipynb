{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a24518-6323-43b4-9960-cf1ded35dffa",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "#### ChromaDB\n",
    "\n",
    "- Use of BM25 in IR \n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aacce9-3653-482a-a9f2-024603a40b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894afc8-e011-417d-ad9c-a7865ed24779",
   "metadata": {},
   "source": [
    "using **books CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dfb58b-e261-419a-a8af-257eb883e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the books csv\n",
    "# https://www.kaggle.com/datasets/saurabhbagchi/books-dataset/data\n",
    "file_path = r'D:\\AI-DATASETS\\02-MISC-large\\books.csv'\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1', sep=';', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9f4a55-3e9b-450b-be6d-ceb3cd8329e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271360, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5919a00d-afab-4e14-97d1-d18530534e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Image-URL-S', 'Image-URL-M',\t'Image-URL-L'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2123f3ee-a965-4fd0-b4f4-2b67668933a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138990</th>\n",
       "      <td>0385310250</td>\n",
       "      <td>Sudden Exposure: A Jill Smith Mystery (Jill Sm...</td>\n",
       "      <td>Susan Dunlap</td>\n",
       "      <td>1996</td>\n",
       "      <td>Bantam Dell Pub Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180016</th>\n",
       "      <td>0373075170</td>\n",
       "      <td>One Last Chance (American Heroes) (Silhouette ...</td>\n",
       "      <td>Justine Davis</td>\n",
       "      <td>1993</td>\n",
       "      <td>Silhouette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214639</th>\n",
       "      <td>003016656X</td>\n",
       "      <td>Prisoners of the Scrambling Dragon</td>\n",
       "      <td>F. N. Monjo</td>\n",
       "      <td>1980</td>\n",
       "      <td>Henry Holt &amp;amp; Co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144511</th>\n",
       "      <td>0195072790</td>\n",
       "      <td>Understanding Depression: A Complete Guide to ...</td>\n",
       "      <td>Donald F., M.D. Klein</td>\n",
       "      <td>1992</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194728</th>\n",
       "      <td>0471197335</td>\n",
       "      <td>Corporate Information Factory</td>\n",
       "      <td>William H. Inmon</td>\n",
       "      <td>1997</td>\n",
       "      <td>John Wiley &amp;amp; Sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256269</th>\n",
       "      <td>3806819580</td>\n",
       "      <td>Japanische KÃ?Â¼che. Einfach gut.</td>\n",
       "      <td>Marianne Kaltenbach</td>\n",
       "      <td>1998</td>\n",
       "      <td>Falken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213169</th>\n",
       "      <td>0451521811</td>\n",
       "      <td>A Girl of the Limberlost</td>\n",
       "      <td>Gene S. Porter</td>\n",
       "      <td>1991</td>\n",
       "      <td>New Amer Library Classics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218249</th>\n",
       "      <td>0684807572</td>\n",
       "      <td>BRAINSTYLES : Change Your Life Without Changin...</td>\n",
       "      <td>Marlene Miller</td>\n",
       "      <td>1997</td>\n",
       "      <td>Simon &amp;amp; Schuster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12290</th>\n",
       "      <td>0743203232</td>\n",
       "      <td>The Nature of Water and Air</td>\n",
       "      <td>Regina McBride</td>\n",
       "      <td>2001</td>\n",
       "      <td>Touchstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171737</th>\n",
       "      <td>0297794868</td>\n",
       "      <td>Boadicea's chariot: The warrior queens</td>\n",
       "      <td>Antonia Fraser</td>\n",
       "      <td>1988</td>\n",
       "      <td>Weidenfeld and Nicolson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "138990  0385310250  Sudden Exposure: A Jill Smith Mystery (Jill Sm...   \n",
       "180016  0373075170  One Last Chance (American Heroes) (Silhouette ...   \n",
       "214639  003016656X                 Prisoners of the Scrambling Dragon   \n",
       "144511  0195072790  Understanding Depression: A Complete Guide to ...   \n",
       "194728  0471197335                      Corporate Information Factory   \n",
       "256269  3806819580                  Japanische KÃ?Â¼che. Einfach gut.   \n",
       "213169  0451521811                           A Girl of the Limberlost   \n",
       "218249  0684807572  BRAINSTYLES : Change Your Life Without Changin...   \n",
       "12290   0743203232                        The Nature of Water and Air   \n",
       "171737  0297794868             Boadicea's chariot: The warrior queens   \n",
       "\n",
       "                  Book-Author Year-Of-Publication                  Publisher  \n",
       "138990           Susan Dunlap                1996      Bantam Dell Pub Group  \n",
       "180016          Justine Davis                1993                 Silhouette  \n",
       "214639            F. N. Monjo                1980        Henry Holt &amp; Co  \n",
       "144511  Donald F., M.D. Klein                1992    Oxford University Press  \n",
       "194728       William H. Inmon                1997      John Wiley &amp; Sons  \n",
       "256269    Marianne Kaltenbach                1998                     Falken  \n",
       "213169         Gene S. Porter                1991  New Amer Library Classics  \n",
       "218249         Marlene Miller                1997       Simon &amp; Schuster  \n",
       "12290          Regina McBride                2001                 Touchstone  \n",
       "171737         Antonia Fraser                1988    Weidenfeld and Nicolson  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02e6e2c-4fe9-41e9-83d2-29feefadabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,re\n",
    "#import spacy\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25777b3b-f02f-4977-a573-9a496e0d5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #print(f\"Original text: {text}\")\n",
    "    \n",
    "    text = text.lower()  # Lowercasing\n",
    "    #print(f\"Lowercased text: {text}\")\n",
    "    \n",
    "    # Remove all punctuation except '&'\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation.replace('&', '')))\n",
    "    #print(f\"Without punctuation (keeping '&'): {text}\")\n",
    "    \n",
    "    text = text.strip()  # Remove leading/trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove excessive whitespace using regex\n",
    "    #print(f\"Without excessive whitespace: {text}\")\n",
    "    \n",
    "    # Normalize &amp; if it exists\n",
    "    text = re.sub(r'&amp;', 'and', text)\n",
    "    #print(f\"After replacing '&amp;': {text}\")\n",
    "    \n",
    "    # Replace any remaining & with 'and'\n",
    "    text = text.replace('&', 'and')\n",
    "    #print(f\"After replacing '&': {text}\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3e8dd4-7623-4d9e-a46f-1c3dc1fa569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is an example with excessive and whitespace\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sample_text = \"This is an example   with   excessive  & whitespace!\"\n",
    "cleaned_text = preprocess_text(sample_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707fec42-b64f-4f10-a877-b44556fbc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any null values\n",
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45a5233e-25b6-495b-a722-425cb6343f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.69 s\n",
      "Wall time: 4.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply the preprocessing\n",
    "df_cleaned['text'] = df_cleaned['Book-Title'] + ' ' + df_cleaned['Book-Author'] + ' ' + df_cleaned['Publisher']\n",
    "df_cleaned['text'] = df_cleaned['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b69cf4-24ba-48a6-aff8-ba855aafaf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271356, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a241ce3-b0cf-4274-83ac-3e142c9825f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 271356 entries, 0 to 271359\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 271356 non-null  object\n",
      " 1   Book-Title           271356 non-null  object\n",
      " 2   Book-Author          271356 non-null  object\n",
      " 3   Year-Of-Publication  271356 non-null  object\n",
      " 4   Publisher            271356 non-null  object\n",
      " 5   text                 271356 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de065716-9659-46bd-9477-b3338758d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_samples = df_cleaned.sample(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37f73d03-6ab2-42f3-86ce-8aee099ad2ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the TF-IDF vectorizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ed0f4a-f770-40b4-a940-b0d6f68a9a4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate TF-IDF vectors for the reviews\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df_cleaned_samples\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate TF-IDF vectors for the reviews\n",
    "tfidf_matrix = vectorizer.fit_transform(df_cleaned_samples.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b222e5-0392-44d5-a324-ca738ef8fe64",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215bcd2-332a-4644-8602-4d6a27094565",
   "metadata": {},
   "source": [
    "BM25 (Best Matching 25) is a ranking function used in information retrieval systems to evaluate the relevance of documents in relation to a query. It builds upon the probabilistic information retrieval model and is particularly effective for scoring and ranking documents based on the frequency of query terms within them. Here's a breakdown of BM25 and its differences from TF-IDF:\n",
    "\n",
    "**Relevance Scoring:** BM25 calculates a score for each document based on the presence and frequency of the terms in the query. The score reflects how well the document matches the query.\n",
    "\n",
    "**Components:**\n",
    "\n",
    "- **Term Frequency (TF):** Similar to TF-IDF, BM25 considers how often a term appears in a document. However, it uses a saturation function to diminish the effect of term frequency as it increases.\n",
    "  \n",
    "- **Inverse Document Frequency (IDF):** BM25 employs IDF to account for the rarity of terms. Rare terms contribute more to the score than common terms.\n",
    "  \n",
    "- **Document Length Normalization:** BM25 normalizes for document length, ensuring that longer documents do not have an unfair advantage simply because they contain more terms.\n",
    "  \n",
    "- **Parameters:** BM25 has parameters like `k1` (controls the impact of term frequency) and `b` (adjusts the normalization based on document length). This flexibility allows for tuning based on specific datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34983c3-4b59-4b92-981a-0918260dc19f",
   "metadata": {},
   "source": [
    "##### Why We Need to Saturate the Term Frequency (TF)\n",
    "\n",
    "##### 1. Diminishing Returns on Term Relevance\n",
    "- As the frequency of a term in a document increases, its contribution to relevance does not increase linearly. In fact, the impact of additional occurrences of the term diminishes.\n",
    "- For instance, if a document mentions a keyword 1 time, it may be relevant; if it mentions it 10 times, it doesn't necessarily mean it is 10 times more relevant. Saturation accounts for this diminishing returns effect.\n",
    "\n",
    "##### 2. Avoiding Overemphasis on Frequent Terms\n",
    "- Without saturation, documents with very high term frequencies might be unfairly prioritized, even if the actual content and relevance to the query are low.\n",
    "- This is particularly important for documents that may repeat a term excessively, as they could skew the results and lead to poor search quality.\n",
    "\n",
    "##### 3. Enhancing Precision in Ranking\n",
    "- Saturation helps create a more balanced scoring system. It allows for a better distinction between documents with varying term frequencies.\n",
    "- For example, a document with a term frequency of 5 might be seen as more relevant than one with a frequency of 1, but not overwhelmingly so. The use of saturation can help refine the score, ensuring the ranking is more precise and meaningful.\n",
    "\n",
    "##### 4. Consistency Across Document Lengths\n",
    "- Different documents can vary significantly in length, leading to variations in raw term frequencies. Saturation helps normalize these differences.\n",
    "- This is particularly important for long documents where high term frequency might be a result of sheer length rather than actual relevance.\n",
    "\n",
    "##### 5. Parameter Control\n",
    "- Saturation provides a means to control the behavior of the scoring function through parameters like `k1`. By adjusting this parameter, users can fine-tune how quickly the effects of term frequency diminish, allowing for flexibility based on specific datasets and requirements.\n",
    "\n",
    "##### Example of Term Frequency Saturation\n",
    "Consider a term \"machine learning\" in two documents:\n",
    "\n",
    "- **Document A:** \"Machine learning is a fascinating field. Machine learning can change the world.\"\n",
    "- **Document B:** \"Machine learning is machine learning machine learning machine learning machine learning machine learning.\"\n",
    "\n",
    "- **Without Saturation:** Document B might score much higher due to the raw count of term occurrences (5 times).\n",
    "- **With Saturation:** Document A might still score higher or similarly due to its context and meaningful use of the term, even though it appears less frequently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74f362-5245-474e-b450-9c42acfb558f",
   "metadata": {},
   "source": [
    "#### 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "Inverse Document Frequency (IDF) in BM25 is conceptually similar to IDF in TF-IDF, but there are some differences in how they are calculated and used in their respective formulas. Here’s a breakdown of the similarities and differences:\n",
    "\n",
    "`Similarities`\n",
    "\n",
    "`Purpose`: Both IDF measures are designed to reflect the importance of a term across a collection of documents. The primary goal is to reduce the weight of common terms and increase the weight of rare terms in the scoring process.\n",
    "\n",
    "`Concept`: In both cases, IDF is based on the idea that terms that appear in many documents are less informative than terms that appear in fewer documents. Therefore, IDF contributes to emphasizing the significance of rarer terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6c2de-fdbb-4cfe-bd3d-6cb37019caa8",
   "metadata": {},
   "source": [
    "`Differences`\n",
    "\n",
    "1. Mathematical Formulation:\n",
    "   \n",
    "- `TF-IDF IDF`:\n",
    "\n",
    "$$\n",
    "\\operatorname{IDF}(t)=\\log \\left(\\frac{N}{\\operatorname{df}(t)}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Where $N$ is the total number of documents and $\\operatorname{df}(t)$ is the number of documents containing the term $t$.\n",
    "\n",
    "- `BM25 IDF`:\n",
    "\n",
    "$$\n",
    "\\operatorname{IDF}(t)=\\log \\left(\\frac{N-\\operatorname{df}(t)+0.5}{\\operatorname{df}(t)+0.5}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "In BM25, a smoothing factor (0.5) is added to both the numerator and denominator to prevent division by zero and to smooth the effect of terms that appear in very few documents.\n",
    "\n",
    "2. Normalization:\n",
    "   \n",
    "- BM25 applies a more nuanced form of normalization, which makes the IDF component more robust in cases where terms are either very common or very rare. The added constants help avoid extreme values, making the model more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849bd02-7e03-405d-b3df-edeb2c9d97a3",
   "metadata": {},
   "source": [
    "#### 3. Document Length Normalization in BM25\n",
    "\n",
    "BM25 incorporates document length normalization to ensure that longer documents do not have an unfair advantage in the scoring process simply because they contain more terms. \n",
    "\n",
    "`How Normalization is Achieved:`\n",
    "1. **Length Parameters**: BM25 uses a parameter \\( b \\) (typically set between 0 and 1) to control the degree of normalization. A value of \\( b = 1 \\) applies full normalization, while \\( b = 0 \\) means no normalization.\n",
    "2. **Length Calculation**: The document length is measured in terms of the total number of terms. BM25 compares this length against the average document length in the collection.\n",
    "3. **Score Adjustment**: The normalization is applied during the score calculation. It adjusts the term frequency based on the length of the document relative to the average length, reducing the score for longer documents while increasing it for shorter ones.\n",
    "\n",
    "#### Example:\n",
    "- **Document A** (100 words) contains the term \"AI\" 10 times.\n",
    "- **Document B** (200 words) also contains the term \"AI\" 20 times.\n",
    "\n",
    "Without normalization, Document B would have a higher score due to higher term frequency. However, BM25 adjusts for this by taking into account the document lengths, ensuring that Document A's relevance is appropriately recognized despite its shorter length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46fc76-28d8-4a00-8d9e-7fa0768c2495",
   "metadata": {},
   "source": [
    "#### BM25 Formula\n",
    "The BM25 scoring function can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\operatorname{BM} 25(d, q)=\\sum_{i=1}^{|q|} I D F\\left(t_i\\right) \\cdot \\frac{T F\\left(t_i, d\\right) \\cdot\\left(k_1+1\\right)}{T F\\left(t_i, d\\right)+k_1 \\cdot\\left(1-b+b \\cdot \\frac{|d|}{\\text { avgdl }}\\right)}\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $d=$ document\n",
    "- $q=$ query\n",
    "- $t_i=$ term in the query\n",
    "- $T F\\left(t_i, d\\right)=$ term frequency of $t_i$ in document $d$\n",
    "- $|d|=$ length of the document (number of terms)\n",
    "- $\\operatorname{avgdl}=$ average document length across the corpus\n",
    "- $I D F\\left(t_i\\right)=$ inverse document frequency of term $t_i$\n",
    "- $k_1$ and $b=$ tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e4276f-a769-4e79-baa9-5fff43e11650",
   "metadata": {},
   "source": [
    "#### Implementing BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acece50-c8ca-43d2-96eb-d31bb779d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e11cacba-8711-4352-90b0-9207b593688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'text' column for BM25\n",
    "tokenized_corpus = [nltk.word_tokenize(text.lower()) for text in df_cleaned_samples['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62e33612-26a2-4460-b14c-50ee37ac6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['thats', 'why', 'theyre', 'in', 'cages', 'people', 'joel', 'perry', 'alyson', 'pubns'], ['frauen', 'die', 'geschichte', 'schrieben', '30', 'portrãâ¤ts', 'von', 'maria', 'sibylla', 'merian', 'bis', 'sophie', 'scholl', 'irma', 'hildebrandt', 'diederichs'], ['mr', 'potters', 'pet', 'dick', 'kingsmith', 'hyperion', 'books', 'for', 'children']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe6534cf-04ac-4ce1-936e-6f100748ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BM25 with the tokenized corpus\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b45501b-8dd6-4b77-8bcd-3146c4ca581c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26938                 beaches iris rainer dart bantam books\n",
       "124158    the eighth day of the week a novel alfred copp...\n",
       "83207     kundalini yoga the flow of eternal power shakt...\n",
       "47985     loveland pinnacle historical romance jane ande...\n",
       "196071    eric liddell pure gold a new biography of the ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_samples.text.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f78cd802-ecc0-4770-9494-6469f198f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query = \"kundalini yoga\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f1fd2fd-724d-44b4-b175-3ad34864a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the query\n",
    "tokenized_query = nltk.word_tokenize(query.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2ffcd99-d333-4935-8b40-492470c025b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kundalini', 'yoga']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af3c2778-fc2c-4936-9f0c-645ca1090f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BM25 scores for the query\n",
    "scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e3083f8-a5ed-4402-a6d5-f29c59534211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2787e7f0-f9b6-48bd-8e04-a00e97eb8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Book-Title  BM25_Score\n",
      "83207           Kundalini Yoga: The Flow of Eternal Power   12.691831\n",
      "67648                              Yoga fÃ?Â¼r jeden Tag.    7.754130\n",
      "67554   The Yoga Manual: A Step-By-Step Guide to Gentl...    5.164993\n",
      "78239                      Cloak of Deception (Star Wars)    0.000000\n",
      "240450  The TROUBLE WITH TESTOSTERONE : And Other Essa...    0.000000\n",
      "...                                                   ...         ...\n",
      "211400  Exploring Missouri Wine Country (Show Me Misso...    0.000000\n",
      "189881  Herman Melville : Redburn, White-Jacket, Moby-...    0.000000\n",
      "65753                                  Reach The Splendor    0.000000\n",
      "114957  The Power of Ethical Persuasion: From Conflict...    0.000000\n",
      "143470  Wit'ch Storm (The Banned and the Banished, Boo...    0.000000\n",
      "\n",
      "[2500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort the results by score in descending order and retrieve the top matches\n",
    "df_cleaned_samples['BM25_Score'] = scores\n",
    "results = df_cleaned_samples.sort_values(by='BM25_Score', ascending=False)\n",
    "\n",
    "print(results[['Book-Title', 'BM25_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fc7be-7241-47f0-a177-cd085efc2bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ae9fb6-5d7b-4e54-899a-63b61393719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3a9a8-1c75-4830-891d-f1645876f886",
   "metadata": {},
   "source": [
    "#### models in openAI\n",
    "------------------------------------\n",
    "\n",
    "OpenAI provides a variety of models, each suited for different use cases, ranging from text generation, code generation, to specific tasks like question answering, summarization, and more.\n",
    "\n",
    "| Model Type               | Description                                                                                       | Model ID               | Variants/Use Cases                                           |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|\n",
    "| **GPT-4 Models**         | The most advanced language model, designed for a wide range of tasks, including text completion and complex reasoning. | `gpt-4`                | Variants: `gpt-4`, `gpt-4-32k` (larger context window)     |\n",
    "| **GPT-3.5 Models**       | A slightly earlier version of the GPT-4 model, used for efficient and high-quality completions across various tasks. | `gpt-3.5-turbo`        |                                                             |\n",
    "| **Codex Models**         | Specialized for code generation tasks, including programming in multiple languages.              | `code-davinci-002`, `code-cushman-001` | Use cases: Autocomplete for code, bug fixes, code explanations. |\n",
    "| **Text-Davinci Models**  | One of the most capable models for text generation, document completion, and more.              | `text-davinci-003`     | Use cases: Writing, summarization, text generation.         |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9721bf-006d-431e-a7b3-b98d36f60aca",
   "metadata": {},
   "source": [
    "##### Key Properties of Models:\n",
    "- **Token Limit**: Defines how much input and output the model can handle in a single request. For example:\n",
    "  - GPT-4 has a context length limit of 8,192 tokens, and `gpt-4-32k` can handle up to 32,768 tokens.\n",
    "- **Training Data**: The models are trained on a mixture of publicly available and licensed datasets but have a knowledge cutoff (e.g., GPT-4 has a cutoff in September 2021).\n",
    "\n",
    "Each model has a balance of capability, efficiency, and cost, and you can select the right one depending on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698efb7d-0236-49b2-8b34-6b97113b1836",
   "metadata": {},
   "source": [
    "#### Endpoints\n",
    "-----------------------------\n",
    "\n",
    "- OpenAI provides several API endpoints that enable developers to interact with their models for various tasks such as `text generation`, `conversation`, `code completion`, `embedding generation`, and more.\n",
    "\n",
    "- Each endpoint serves a different purpose and can be accessed via HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6319975-cfda-4b44-aa87-db386998ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for older 0.28 API\n",
    "# Make a request to the Completions Endpoint\n",
    "# response = openai.Completion.create(\n",
    "#   model       = \"gpt-3.5-turbo\",                                # Specify the model you want to use\n",
    "#   prompt      = \"Once upon a time, there was a wise owl that\",  # Input prompt\n",
    "#   max_tokens  = 50,                                             # The maximum number of tokens to generate\n",
    "#   temperature = 0.7,                                            # Controls randomness (0.7 = moderate creativity)\n",
    "#   n           = 1,                                              # The number of completions to generate\n",
    "#   stop        = None                                            # Optional stop sequence\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045a6097-8ca1-42f8-9ead-33b1d33b0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the generated completion\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3a040-0ba3-49ea-8193-dc683cf59966",
   "metadata": {},
   "source": [
    "#### 2. Chat Completion Endpoint (/v1/chat/completions)\n",
    "\n",
    "**Purpose**: Designed for GPT models (GPT-3.5, GPT-4) to handle conversation-like inputs, but can be used for tasks similar to text generation.\n",
    "\n",
    "**API Endpoint**: POST https://api.openai.com/v1/chat/completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c26bd8-034d-4d69-a9a1-5f43f0abd7b0",
   "metadata": {},
   "source": [
    "\n",
    "**Usage**: It’s the recommended endpoint for most tasks, including text completion, Q&A, summarization, etc., by providing a chat history as input.\n",
    "\n",
    "**Key Parameters**:\n",
    "\n",
    "- **model**: Specifies the model to be used (e.g., gpt-4 or gpt-3.5-turbo).\n",
    "- **messages**: A list of messages, where each message contains:\n",
    "  - **role**: Either \"system\", \"user\", or \"assistant\".\n",
    "  - **content**: The text for the message.\n",
    "- **max_tokens**: Controls how many tokens to generate.\n",
    "- **temperature**: Controls randomness in the output (higher value = more random).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e571e8-49ac-4e33-8d94-de869faa31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7d35b0-8280-49a3-bcb2-de3ebe2366a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # api_key = openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58eeb229-08d8-45d8-b061-f730ee5b3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the Chat Completion Endpoint\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",  # Specify the model\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Can you summarize the key parameters for the Chat Completion Endpoint?\"}\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd5b2dd-3b0e-40a6-918c-10a9e8b411f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The key parameters for the Chat Completion Endpoint typically include:\n",
      "\n",
      "1. Chat ID: A unique identifier for the chat session that needs to be completed.\n",
      "2. Completion Status: A flag indicating whether the chat session was successfully completed or not.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e7597b-5688-47df-9815-5e733a9c9c68",
   "metadata": {},
   "source": [
    "In OpenAI's API for language models, messages are the fundamental building blocks of prompts. \n",
    "\n",
    "Each message typically consists of two main components: the `role` of the sender and the `content` of the message. \n",
    "\n",
    "| **Role**   | **Description**                                                                                                                                                 | **Example**                                                                                                                  |\n",
    "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| User       | Represents the end user or the application initiating the conversation. Sends input messages, asking questions or providing information for the model's response. | If a user asks, \"What is machine learning?\", the message is sent with the role of \"user\".                                  |\n",
    "| Assistant  | Represents the AI model's responses to the user’s queries. Generates replies based on the context and content of previous messages, aiming to be helpful and informative. | After the user asks about machine learning, the assistant might respond, \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\" |\n",
    "| System     | Provides initial instructions or context to the assistant to guide its behavior throughout the interaction. Typically used to set the tone, rules, or constraints of the assistant’s responses. | A system message might state, \"You are a friendly and informative assistant.\"                                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492db523-c152-43de-83ba-4cf5a94995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  {\"role\": \"system\",    \"content\": \"You are a knowledgeable assistant.\"},\n",
    "  {\"role\": \"user\",      \"content\": \"Can you tell me about neural networks?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Neural networks are a series of algorithms that mimic \\\n",
    "                                    the operations of a human brain to recognize relationships in a set of data.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faeb7a47-5318-481b-b504-9ade8cc2a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    #api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9746244a-16c7-4b4f-8c21-910e14f33fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts \\\n",
    "                                   with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5209083-3a1a-45d5-a459-fa847494855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AF1WQneyZIKYopPGD6d7sNu054AvM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In coding's dance, recursion plays,\\nA loop where function calls itself ablaze.\\nLike a mirror reflecting endless grace,\\nSolving problems in a recursive embrace.\\nEach iteration peels back layers deep,\\nIn a hypnotic rhythm, algorithms leap.\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1728144134, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=49, prompt_tokens=46, total_tokens=95, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0), prompt_tokens_details={'cached_tokens': 0}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92e3474-dfcf-46b2-a34a-d1c678700488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10e4538e-7988-4f39-aa63-f7b4f7b8510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'length',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'content': 'Sure! The key parameters for the Chat '\n",
      "                                     'Completion Endpoint typically include:\\n'\n",
      "                                     '\\n'\n",
      "                                     '1. Chat ID: A unique identifier for the '\n",
      "                                     'chat session that needs to be '\n",
      "                                     'completed.\\n'\n",
      "                                     '2. Completion Status: A flag indicating '\n",
      "                                     'whether the chat session was '\n",
      "                                     'successfully completed or not.\\n'\n",
      "                                     '3',\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant'}}],\n",
      " 'created': 1728143166,\n",
      " 'id': 'chatcmpl-AF1GoIbcGCnRQRzTXzL5XfOjCt5SG',\n",
      " 'model': 'gpt-3.5-turbo-0125',\n",
      " 'object': 'chat.completion',\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 50,\n",
      "           'completion_tokens_details': {'reasoning_tokens': 0},\n",
      "           'prompt_tokens': 19,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0},\n",
      "           'total_tokens': 69}}\n"
     ]
    }
   ],
   "source": [
    "# Pretty print the response using pprint\n",
    "pprint(response.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db51b1-edfa-45b7-a42e-f722c3849ac5",
   "metadata": {},
   "source": [
    "**Choices**\n",
    "\n",
    "| Attribute               | Description                                                                                              |\n",
    "|-------------------------|----------------------------------------------------------------------------------------------------------|\n",
    "| **finish_reason**        | The reason the completion finished (e.g., `'stop'`).                                                     |\n",
    "| **index**                | The index of the choice in the list.                                                                     |\n",
    "| **logprobs**             | Any associated log probabilities (in this case, it's `None`).                                            |\n",
    "| **message**              | An instance of `ChatCompletionMessage` that contains:                                                    |\n",
    "| - **content**            | The actual text generated by the model (e.g., a poem about recursion).                                   |\n",
    "| - **role**               | The role of the entity that generated the message (e.g., `'assistant'`).                                 |\n",
    "| - **function_call**      | Information if the message included a function call (in this case, it's `None`).                         |\n",
    "| - **tool_calls**         | Information if there were any tool calls (also `None` in this case).                                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fe314-f578-46ad-b92b-84ddaeec8bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f54539-fb0a-4419-a493-4f362e4232bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc6e3674-08b0-4c8b-b394-984343d736de",
   "metadata": {},
   "source": [
    "#### Exercise - 01 \n",
    "\n",
    "- (extract pieces of info from the completion response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620a096-3aa3-4489-8bf1-21eb2a415836",
   "metadata": {},
   "source": [
    "Qs : Extract the model name from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb2d552-39cb-4193-85a8-b89fe4bcb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa32315a-6025-42fb-afce-b5cb40e4e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "# Expected solution\n",
    "model_name = response.to_dict()['model']\n",
    "print(\"Model used:\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d5d57-ea4e-4f47-a621-860b8c57f22e",
   "metadata": {},
   "source": [
    "Qs : Extract the content of the assistant’s reply from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68995355-32e1-489b-964c-bf031402b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant's reply: The Los Angeles Dodgers won the World Series in 2020, defeating the Tampa Bay Rays.\n"
     ]
    }
   ],
   "source": [
    "# Expected solution\n",
    "assistant_reply = response.to_dict()['choices'][0]['message']['content']\n",
    "print(\"Assistant's reply:\", assistant_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d101a5f2-a99e-434e-899d-a1df63440927",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c8706-1ba2-42c1-b95b-026d8212ee29",
   "metadata": {},
   "source": [
    "Qs : Create a dictionary of World Series winners by year from the assistant’s reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5361ffca-0a2a-4488-8a98-a23e0c1270d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winners of the World Series for the years you mentioned are as follows:\n",
      "\n",
      "- **2020**: Los Angeles Dodgers\n",
      "- **2021**: Atlanta Braves\n",
      "- **2022**: Houston Astros\n",
      "- **2023**: Texas Rangers\n",
      "\n",
      "If you need more information about any of these seasons or teams, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "print(winners_by_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561901af-93af-42eb-b359-6f0985ef0d00",
   "metadata": {},
   "source": [
    "Get the output in a dictionary format, year : winner name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f7002c3-ee55-4d08-b683-51333fd5a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ? \\\n",
    "                                       Provide the answer in a dictionary format as below \\\n",
    "                                       year : winner name \\\n",
    "                                       \"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "163d9bf0-5392-4919-9dd6-f63e0268d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information in the requested dictionary format:\n",
      "\n",
      "```python\n",
      "{\n",
      "    2020: \"Los Angeles Dodgers\",\n",
      "    2021: \"Atlanta Braves\",\n",
      "    2022: \"Houston Astros\",\n",
      "    2023: \"Texas Rangers\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "print(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce26a81-b0ed-4745-82de-3aced42c1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": '''Who won the world series in 2020, 2021, 2022, 2023 ? \\\n",
    "                                       Provide the answer in a dictionary format as below \\\n",
    "                                       {\n",
    "                                           year : winner name \n",
    "                                       }\n",
    "                                       without any extra text\n",
    "                                       \\\n",
    "                                       '''},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29d688-8bb1-4af0-979d-f061ad80daa0",
   "metadata": {},
   "source": [
    "Qs : load the output in dataframe format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3fd63-2e3e-443c-a746-574eac87916d",
   "metadata": {},
   "source": [
    "| Year | Winner                |\n",
    "|------|-----------------------|\n",
    "| 2020 | Los Angeles Dodgers   |\n",
    "| 2021 | Atlanta Braves        |\n",
    "| 2022 | Houston Astros        |\n",
    "| 2023 | Texas Rangers         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f7433b2-7732-4890-80ed-2de891a2d61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    2020: \"Los Angeles Dodgers\",\\n    2021: \"Atlanta Braves\",\\n    2022: \"Houston Astros\",\\n    2023: \"Texas Rangers\"\\n}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example solution\n",
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "winners_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b406c896-26e1-454a-9a6c-2bf74fbc192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e9b5304-b9c3-4913-bc67-8cb1481fed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string representation of the dictionary to an actual dictionary\n",
    "world_series_dict = ast.literal_eval(winners_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82cea6b5-7b99-4108-bc46-f629ca310c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Atlanta Braves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>Houston Astros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Texas Rangers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year               Winner\n",
       "0  2020  Los Angeles Dodgers\n",
       "1  2021       Atlanta Braves\n",
       "2  2022       Houston Astros\n",
       "3  2023        Texas Rangers"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(list(world_series_dict.items()), columns=['Year', 'Winner'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d68a97-2f31-4feb-af69-08fab5ef3230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
